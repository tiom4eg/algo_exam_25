\section{Внешняя память}

В реальном мире основным боттлнеком являются дисковые операции, поэтому в этом разделе мы постараемся оптимизировать уже известные алгоритмы под работу с внешней памятью. Стандартные обозначения: $B$ - размер блока памяти, который считывается за одну операцию, $M$ - размер имеющейся оперативной памяти (в которой операции будут выполняться за символическое $O(0)$), $N$ - число операций или размер данных.

Самая базовая задача - пройтись по какому-то массиву в памяти и что-то в нём найти/посчитать какую-то статистику. Если массив лежит во внешней памяти подряд, то будем считывать в оперативную память по $B$ элементов за раз, обновлять статистику, считывать следующий блок и так далее. Если мы хотим произвести какую-то трансформацию (например, превратить массив чисел в массив префсумм), то можно модицифировать загруженный блок и вернуть его на старое место также одной операцией. Данную операцию далее будем называть $Scan(N)$ и она работает за $O(\frac{N}{B})$ операций.

Реализуем стек во внешней памяти. Изначально будем в RAM хранить пустой блок размера $B$. Как поддерживать операции стека на нём - очевидно. Дождёмся первого момента, когда этот блок полностью заполнится и положим его в память, при этом сохраним его в RAM. Далее, те элементы, которые не влезают в первый блок, будем добавлять во второй, пока и он не переполнится, после чего мы положим его в память вслед за прошлым положенным, поменяем с первым блоком и очистим второй. То есть, мы хотим хранить в RAM последний полный блок стека + текущий неполный. Если мы в какой-то момент опустошим первый блок, то полезем в память, чтобы забрать оттуда новый блок. Почему это работает за $O(\frac{1}{B})$ на операцию в худшем случае? Очевидно, что нужно хотя бы $B$ операций с момента прошлой записи блока в память, чтобы мы заполнили ещё один блок и записали в память его. Проблему могут доставлять операции \texttt{pop}. Но из-за того, что мы храним в RAM, гарантируется, что после последнего доступа в внешнюю память с целью забрать блок до нового доступа пройдет хотя бы $B$ операций (поскольку после очередного чтения из памяти, в RAM хранится хотя бы $B$ элементов, чтобы запросить новый доступ, их все нужно удалить).

Имея реализацию стека, можно написать очередь на двух стеках (из переднего стека только забираем элементы, в задний только добавляем) и дек на двух стеках (здесь они уже используются на полную мощность). Примерно такими же манипуляциями, как и для стека, можно доказать, что все работает за $O(\frac{1}{B})$ на операцию.

Наконец, опишем идею для реализации сортировки во внешней памяти за $O(\frac{N}{B} \log_{\frac{M}{B}} \frac{N}{M})$ (эту же идею можно переделать, чтобы получить кучу с такой же асимптотикой). По сути, будем строить дерево merge сортировки, только вместо 2 детей будем объединять $\frac{M}{B}$ за раз (больше не влезет в RAM). В листьях дерева будем хранить отсортированные блоки размера $M$ - подгрузим их в RAM, отсортируем и загрузим обратно. Теперь, пусть мы хотим смержить $\frac{M}{B}$ кусков. Будем подгружать их в память блоками размера $B$. Далее, в RAM можем мержить их примерно как угодно, например можно завести приоритетную очередь и доставать оттуда по одному минимальному элементу. Когда в каком-то из блоков закончятся элементы, возьмём следующий (или ничего не возьмём, если элементов не осталось). Заполненные блоки, полученные в результате мержа, закинем друг за другом во внешнюю память, пометив, что в этом месте у нас лежит массив очередной вершины дерева сортировки. Поскольку каждый блок размера $B$ исходного массива будет обработан в $\log_{\frac{M}{B}} \frac{N}{M}$ вершинах дерева (поскольку именно такая высота будет у дерева сортировки), получим желаемую асимптотику. Процедура сортировки с такой асимптотикой является оптимальной и обозначается как $Sort(N)$.
